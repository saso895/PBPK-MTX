"""
è‡ªå†™ Metropolis-Hastings é‡‡æ ·å™¨ï¼Œç”¨ 0427_Powell åˆæ­¥æ‹Ÿåˆç»“æœåšå…ˆéªŒä¸­å¿ƒã€‚
é‡‡å®Œé“¾åæŠŠåéªŒå‡å€¼ä¿å­˜ä¸º saved_result/mcmc_params0427.pklï¼Œ
å¯ç›´æ¥è¢« Simu.py / simu_plot.py è°ƒç”¨ã€‚
è¿è¡Œæ–¹å¼:
    python mcmc_metropolis0427.py
"""

import numpy as np
from tqdm import tqdm
import pickle, time, os, datetime,pandas as pd
from scipy.integrate import odeint
from joblib import Parallel, delayed
#from tqdm.contrib.concurrent import tqdm_joblib   # è®© joblib ä¹Ÿå¸¦æ€»è¿›åº¦æ¡


# === 1. å¼•å…¥ä½ ç°æœ‰çš„æ¨¡å‹ / æ•°æ® / å¸¸é‡ ===========================
from init_param import (QRest, QK, QL, QPlas, VRest, VK, VL, VPlas,
                        init_pars)
from init_data_point4 import (time_points_train, concentration_data_train,
                              input_dose_train, inject_timelen_train)

# ---------- ä¸ modfit0610.py ä¸­ä¸€è‡´ ----------
def derivshiv(y, t, parms, R, T_total):
    PRest, PK, PL, Kbile, GFR, Free, Vmax_baso, Km_baso, Kurine, Kreab = parms
    input_rate = R if t <= T_total else 0
    ydot = np.zeros(7)
    ydot[0] = (QRest * y[3] / VRest / PRest) + (QK * y[2] / VK / PK) \
            + (QL * y[1] / VL / PL) - (QPlas * y[0] / VPlas) \
            + Kreab * y[4] + input_rate / VPlas
    ydot[1] = QL * (y[0]/VPlas - y[1]/VL/PL) - Kbile * y[1]
    ydot[2] = QK * (y[0]/VPlas - y[2]/VK/PK) - y[0]/VPlas*GFR*Free \
            - (Vmax_baso * y[2] / VK / PK) / (Km_baso + y[2]/VK/PK)
    ydot[3] = QRest * (y[0]/VPlas - y[3]/VRest/PRest)
    ydot[4] = y[0]/VPlas*GFR*Free + (Vmax_baso*y[2]/VK/PK)/(Km_baso+y[2]/VK/PK) \
            - y[4]*Kurine - Kreab*y[4]
    ydot[5] = Kurine * y[4]
    ydot[6] = Kbile * y[1]
    return ydot

def FIT_model(t, D_total, T_total, *params):
    R = D_total / T_total
    y0 = np.zeros(7)
    y = odeint(derivshiv, y0, t, args=(params, R, T_total),
               rtol=1e-6, atol=1e-9, h0=0.1)
    return y[:, 0] / VPlas
# ---------------------------------------------------------------

# === 2. è¯»å…¥ 0427_Powell å…ˆéªŒä¸­å¿ƒ ===============================
with open('saved_result/optimized_params0427_Powell.pkl', 'rb') as f:
    theta_start = pickle.load(f)          # 10 ç»´ ndarray

param_names = ["PRest","PK","PL","Kbile","GFR","Free",
               "Vmax_baso","Km_baso","Kurine","Kreab"]
sigma_start   = 0.6   # ç»™ä¸ªç»éªŒå€¼ï¼šæ®‹å·®(log)çš„SDâ‰ˆ0.5â€“1.0
theta_start   = np.append(theta_start, sigma_start)   # å˜æˆ 11 ç»´
param_names  += ['sigma']  

# === 3. Likelihoodï¼ˆå‡è®¾æ®‹å·® ~ N(0, ÏƒÂ²)ï¼ŒÏƒÂ² å– 1ï¼‰ = -0.5 * RSS ===
def log_likelihood(theta):
    sigma = theta[-1]
    if sigma <= 0:                # æ‹’ç»è´Ÿ Ïƒ
        return -np.inf
    rss = 0.0
    n_tot = 0
    for tp, conc, dose, tinf in zip(time_points_train,
                                    concentration_data_train,
                                    input_dose_train,
                                    inject_timelen_train):
        pred = FIT_model(tp, dose, tinf, *theta[:-1])
        # â€”â€” é˜²æ­¢ log(0)
        EPS  = 1e-6
        pred = np.clip(pred, EPS, None)
        conc = np.clip(conc, EPS, None)

        diff = np.log(pred) - np.log(conc)
        rss += np.sum(diff**2)
        n_tot += diff.size

    # åŒæ­¥æ›´æ–° Ïƒ çš„å…ˆéªŒï¼ˆåŠ Cauchy æˆ– Inv-Gammaï¼‰
    return -0.5*rss/sigma**2 - n_tot*np.log(sigma)

# === 4. Proposalï¼šå¯¹ log(Î¸) åšéšæœºæ¸¸èµ°ï¼Œé«˜ç»´å…±çº¿æ›´ç¨³ ==========
theta_log_start = np.log(theta_start)
step_sizes = 0.05 * np.ones_like(theta_log_start)   # 5% æŠ–åŠ¨ï¼›å¯å¾®è°ƒ

def propose(current_log):
    return current_log + np.random.normal(scale=step_sizes)

# === 5. é‡‡æ ·å‚æ•° ===============================================
n_iter   = 5000       # æ€»è¿­ä»£
burn_in  = 1000       # ä¸¢å¼ƒå‰ burn_in
thin     = 5          # æ¯ thin å–ä¸€æ¬¡ï¼Œå‡å°‘è‡ªç›¸å…³
rng = np.random.default_rng(seed=20240610)
n_chain = 4

# === 6. å•é“¾é‡‡æ ·å‡½æ•° ==============================================
def run_chain(seed,chain_id=None, progress_bar=True):
    rng = np.random.default_rng(seed)
    chain   = np.empty((n_iter, len(theta_start)))
    loglike = np.empty(n_iter)

    curr_log   = theta_log_start.copy()
    curr_theta = theta_start.copy()
    curr_ll    = log_likelihood(curr_theta)
    accept_cnt = 0

    iter_range = range(n_iter)
    if progress_bar:
        desc_txt = f"Chain {chain_id}" if chain_id is not None else "Sampling"
        iter_range = tqdm(iter_range, desc=desc_txt, leave=False)

    for i in iter_range:
        prop_log   = propose(curr_log)
        prop_theta = np.exp(prop_log)
        prop_ll    = log_likelihood(prop_theta)

        if np.log(rng.uniform()) < (prop_ll - curr_ll):
            curr_log, curr_theta, curr_ll = prop_log, prop_theta, prop_ll
            accept_cnt += 1

        chain[i]   = curr_theta
        loglike[i] = curr_ll

    acc_rate = accept_cnt / n_iter
    return chain, loglike, acc_rate
# === 6b. å¤šé“¾è¿è¡Œ ================================================
from tqdm import tqdm
from joblib import Parallel, delayed

if __name__ == "__main__":
    chain_list, loglike_list, acc_rates = [], [], []

    # â€”â€” æ˜¾ç¤ºä¸€ä¸ªæ€»è¿›åº¦æ¡
    with tqdm(total=n_chain, desc="Total sampling") as prog:

        def _run_one_chain(cid):
            chain_c, ll_c, acc_c = run_chain(seed=20240611+cid,
                                             chain_id=cid+1,
                                             progress_bar=False)  # å­è¿›ç¨‹ä¸å¸¦ tqdm
            return chain_c, ll_c, acc_c

        results = Parallel(n_jobs=n_chain)(
            delayed(_run_one_chain)(cid) for cid in range(n_chain)
        )

        for cid, (chain_c, ll_c, acc_c) in enumerate(results, 1):
            chain_list.append(chain_c)
            loglike_list.append(ll_c)
            acc_rates.append(acc_c)
            print(f"é“¾ {cid} å®Œæˆï¼Œæ¥å—ç‡ {acc_c:.2f}")
            prog.update(1)

    # === 7. åéªŒåˆå¹¶ ===============================================
    post_list   = []
    for c in chain_list:
        post_c = c[burn_in::thin]          # shape = (draws, n_param)
        post_list.append(post_c)

    post_all   = np.concatenate(post_list, axis=0)        # (n_chain*draws, n_param)
    theta_post_mean = post_all.mean(axis=0)

    print("\nåéªŒå‡å€¼å‚æ•°ï¼š")
    for name, val in zip(param_names, theta_post_mean):
        print(f"{name:<10} {val:>10.4g}")
    # === 7b. æ”¶æ•›è¯Šæ–­ï¼šå¤šé“¾ R-hat ==================================
    import arviz as az

    # æŠŠæ¯æ¡é“¾çš„ burn / thin åæ•°ç»„å †æˆ (chains, draws, n_param)
    draws_per_chain = post_list[0].shape[0]
    posterior_dict = {
        name: np.stack([pc[:, idx] for pc in post_list])   # shape (n_chain, draws)
        for idx, name in enumerate(param_names)
    }

    idata = az.from_dict(posterior=posterior_dict)

    summary = az.summary(idata, var_names=param_names,
                        round_to=4, filter_vars="like")
    print("\n=== ArviZ æ”¶æ•›è¯Šæ–­ ===")
    print(summary[['mean','r_hat','ess_bulk','ess_tail']])

    if (summary['r_hat'] > 1.01).any():
        print("âš ï¸  å­˜åœ¨ r_hat > 1.01ï¼Œå»ºè®®å»¶é•¿é‡‡æ ·æˆ–è°ƒæ­¥é•¿ã€‚")
    else:
        print("âœ…  r_hat å…¨éƒ¨ â‰¤ 1.01ï¼Œæ”¶æ•›è‰¯å¥½ã€‚")


    # === 8. ä¿å­˜åéªŒå‡å€¼ ============
    os.makedirs('saved_result', exist_ok=True)
    out_path = 'saved_result/mcmc_params0611.pkl'
    with open(out_path,'wb') as f:
        pickle.dump(theta_post_mean, f)
    print(f"\nğŸŒŸ å·²ä¿å­˜åˆ° {out_path}")

    # ------------------------------------------------------------------
    # === 9. æ‰“å°â€œæœ€ç»ˆä¼˜åŒ–å‚æ•°å¯¹æ¯”â€è¡¨ ==================================
    import pandas as pd
    from init_param import init_pars            # â† è¿™æ˜¯ä½ è„šæœ¬é‡ŒåŸå§‹åŸºçº¿å‘é‡

    df_param = pd.DataFrame({
        'å‚æ•°': pd.Series(param_names),
        'åˆå§‹å‚æ•°å€¼': pd.Series(init_pars,               # æ³¨ï¼šè‹¥æƒ³æ¯” Powell å…ˆéªŒå°±æ¢æˆ theta_start
        'MCMCå‡å€¼':  theta_post_mean
    })

    print("\n=== ğŸ† æœ€ç»ˆä¼˜åŒ–å‚æ•°å¯¹æ¯”ï¼ˆMCMCï¼‰ğŸ† ===")
    print(df_param.to_string(index=False))