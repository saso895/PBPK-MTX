"""
è‡ªå†™ Metropolis-Hastings é‡‡æ ·å™¨ï¼Œç”¨ 0427_Powell åˆæ­¥æ‹Ÿåˆç»“æœåšå…ˆéªŒä¸­å¿ƒã€‚
é‡‡å®Œé“¾åæŠŠåéªŒå‡å€¼ä¿å­˜ä¸º saved_result/mcmc_params0427.pklï¼Œ
å¯ç›´æ¥è¢« Simu.py / simu_plot.py è°ƒç”¨ã€‚
è¿è¡Œæ–¹å¼:
    python mcmc_metropolis0427.py
"""

import numpy as np
from tqdm import tqdm, trange
import pickle, time, os, datetime,pandas as pd
from scipy.integrate import odeint
from joblib import Parallel, delayed
import matplotlib.pyplot as plt
from scipy.integrate import solve_ivp
import arviz as az
#from tqdm.contrib.concurrent import tqdm_joblib   # è®© joblib ä¹Ÿå¸¦æ€»è¿›åº¦æ¡


# === 1. å¼•å…¥ä½ ç°æœ‰çš„æ¨¡å‹ / æ•°æ® / å¸¸é‡ ===========================
from init_param import (QRest, QK, QL, QPlas, VRest, VK, VL, VPlas,
                        init_pars)
from init_data_point4 import (time_points_train, concentration_data_train,
                              input_dose_train, inject_timelen_train)

# ---------- ä¸ modfit0610.py ä¸­ä¸€è‡´ ----------
def derivshiv(y, t, parms, R, T_total):
    PRest, PK, PL, Kbile, GFR, Free, Vmax_baso, Km_baso, Kurine, Kreab = parms
    input_rate = R if t <= T_total else 0
    ydot = np.zeros(7)
    ydot[0] = (QRest * y[3] / VRest / PRest) + (QK * y[2] / VK / PK) \
            + (QL * y[1] / VL / PL) - (QPlas * y[0] / VPlas) \
            + Kreab * y[4] + input_rate / VPlas
    ydot[1] = QL * (y[0]/VPlas - y[1]/VL/PL) - Kbile * y[1]
    ydot[2] = QK * (y[0]/VPlas - y[2]/VK/PK) - y[0]/VPlas*GFR*Free \
            - (Vmax_baso * y[2] / VK / PK) / (Km_baso + y[2]/VK/PK)
    ydot[3] = QRest * (y[0]/VPlas - y[3]/VRest/PRest)
    ydot[4] = y[0]/VPlas*GFR*Free + (Vmax_baso*y[2]/VK/PK)/(Km_baso+y[2]/VK/PK) \
            - y[4]*Kurine - Kreab*y[4]
    ydot[5] = Kurine * y[4]
    ydot[6] = Kbile * y[1]
    return ydot
def FIT_model(t, D_total, T_total, *params):
    R = D_total / T_total
    y0 = np.zeros(7)
    
    def rhs(ti, yi):
        return derivshiv(yi, ti, params, R, T_total)
    try:
        sol = solve_ivp(rhs, (t[0], t[-1]), y0,
                        t_eval=t, method='LSODA',
                        rtol=1e-6, atol=1e-9,
                        max_step=0.2)
    except Exception:
        return np.full_like(t, np.nan)  # æ˜¾å¼å¤±è´¥å€¼
    if not sol.success or np.any(np.isnan(sol.y[0])) or np.any(np.isinf(sol.y[0])):
        return np.full_like(t, np.nan)  # æ˜ç¡®å¤±è´¥å¤„ç†

    return sol.y[0] / VPlas

# ---------------------------------------------------------------

# === 2. è¯»å…¥ 0427_Powell å…ˆéªŒä¸­å¿ƒ ===============================
with open('/nfs/home/y18300744/MTXmodel/saved_result/optimized_params0427_Powell.pkl', 'rb') as f:
    theta_start = pickle.load(f)          # 10 ç»´ ndarray

param_names = ["PRest","PK","PL","Kbile","GFR","Free",
               "Vmax_baso","Km_baso","Kurine","Kreab"]
sigma_start   = 0.6   # ç»™ä¸ªç»éªŒå€¼ï¼šæ®‹å·®(log)çš„SDâ‰ˆ0.5â€“1.0
theta_start   = np.append(theta_start, sigma_start)   # å˜æˆ 11 ç»´
param_names  += ['sigma']  

# === 3. Likelihoodï¼ˆå‡è®¾æ®‹å·® ~ N(0, ÏƒÂ²)ï¼ŒÏƒÂ² å– 1ï¼‰ = -0.5 * RSS ===
def log_likelihood(theta):
    sigma = theta[-1]
    if sigma <= 0:                # æ‹’ç»è´Ÿ Ïƒ
        return -np.inf
    rss = 0.0
    n_tot = 0
    for tp, conc, dose, tinf in zip(time_points_train,
                                    concentration_data_train,
                                    input_dose_train,
                                    inject_timelen_train):
        pred = FIT_model(tp, dose, tinf, *theta[:-1])
        if np.any(np.isnan(pred)) or np.any(np.isinf(pred)):
            return -np.inf

        # â€”â€” é˜²æ­¢ log(0)
        EPS  = 1e-6
        pred = np.clip(pred, EPS, None)
        conc = np.clip(conc, EPS, None)

        diff = np.log(pred) - np.log(conc)
        rss += np.sum(diff**2)
        n_tot += diff.size

    # åŒæ­¥æ›´æ–° Ïƒ çš„å…ˆéªŒï¼ˆåŠ Cauchy æˆ– Inv-Gammaï¼‰
    return -0.5*rss/sigma**2 - n_tot*np.log(sigma)

# === 4. Proposalï¼šå¯¹ log(Î¸) åšéšæœºæ¸¸èµ°ï¼Œé«˜ç»´å…±çº¿æ›´ç¨³ ==========
theta_log_start = np.log(theta_start)
step_sizes = 0.05 * np.ones_like(theta_log_start)   # 5% æŠ–åŠ¨ï¼›å¯å¾®è°ƒ

def propose(current_log, rng):
    return current_log + rng.normal(scale=step_sizes)

# === 5. é‡‡æ ·å‚æ•°
#  ===============================================
checkpoint_int = 50000          # â˜…â˜… æ–°ï¼šæ¯ 1ä¸‡ æ­¥å­˜ä¸€æ¬¡ ckpt
resume_path    = ""              # â˜…â˜… æ–°ï¼šç©ºå­—ä¸²=ä¸ç»­è·‘ï¼›å¡«è·¯å¾„å³ç»­
jit_scale = 0.05        # <-- åˆå§‹æŠ–åŠ¨å¹…åº¦ (log ç©ºé—´Â±5 %)
step_report = 20000
n_iter   = 250000      # æ€»è¿­ä»£
burn_in  = 25000       # ä¸¢å¼ƒå‰ burn_in
thin     = 50          # æ¯ thin å–ä¸€æ¬¡ï¼Œå‡å°‘è‡ªç›¸å…³
rng = np.random.default_rng(seed=20240610)
n_chain = 4

# === 6. å•é“¾é‡‡æ ·å‡½æ•° ==============================================
def run_chain(seed,chain_id=None, progress_bar=True):
    rng = np.random.default_rng(seed)
    chain   = np.empty((n_iter, len(theta_start)))
    loglike = np.empty(n_iter)

     # è‹¥å¡«å†™äº† resume_pathï¼Œåˆ™è¦†ç›–åˆå§‹ç‚¹ & RNG çŠ¶æ€ ------------------
    if chain_id == 1 and resume_path and os.path.exists(resume_path):  # â˜…â˜…
        ckpt = pickle.load(open(resume_path, "rb"))
        curr_log = ckpt["phi"]
        rng.bit_generator.state = ckpt["rng"]
        start_iter = ckpt["iter"]
        print(f"â–¶ï¸  ä»æ­¥ {start_iter} ç»­è·‘ (ChainÂ 1)")
    else:
        curr_log = theta_log_start + rng.normal(scale=jit_scale)
        start_iter = 0
 
    #curr_log   = theta_log_start + rng.normal(scale=jit_scale)#â˜…â˜… ä¿®æ”¹ 
    curr_theta = np.exp(curr_log)
    curr_ll    = log_likelihood(curr_theta)
    accept_cnt = 0

    iters = tqdm(range(start_iter, start_iter + n_iter),   # â˜…â˜…
                  desc=f"Chain {chain_id}", leave=False)
    for i in iters:
        prop_log   = propose(curr_log, rng)#â˜…â˜… ä¿®æ”¹ 
        prop_theta = np.exp(prop_log)
        prop_ll    = log_likelihood(prop_theta)

        if np.log(rng.random()) < (prop_ll - curr_ll):#â˜…â˜… ä¿®æ”¹ 
            curr_log, curr_theta, curr_ll = prop_log, prop_theta, prop_ll
            accept_cnt += 1

        idx = i - start_iter
        chain[idx]   = curr_theta
        loglike[idx] = curr_ll

        # === â˜…â˜… checkpointï¼šæ¯ 10 k æ­¥ dump =====================
        if (i + 1) % checkpoint_int == 0:
            ck_path = f"ckpt_chain{chain_id}_{i+1}.pkl"
            pickle.dump({
                "iter":   i + 1,
                "phi":    curr_log,
                "theta":  curr_theta,
                "ll":     curr_ll,
                "rng":    rng.bit_generator.state,
            }, open(ck_path, "wb"))
            print(f"ğŸ’¾ å·²ä¿å­˜ {ck_path}")

    acc_rate = accept_cnt / n_iter
    ll_mean  = loglike[burn_in:].mean()        # <<< PATCH â‘¢
    return chain, loglike, acc_rate,ll_mean
# === 6b. å¤šé“¾è¿è¡Œ ================================================
from tqdm import tqdm
# ==== â˜… æ–°å¢ï¼šå¹¶è¡Œé‡‡æ ·æ‰€éœ€ ====
from joblib import Parallel, delayed          # â˜…

if __name__ == "__main__":
    results = Parallel(n_jobs=n_chain, prefer="processes")(    # <<< PATCH â‘£
        delayed(run_chain)(seed=20240611 + cid, chain_id=cid+1)
        for cid in range(n_chain)
    )
    chain_list, loglike_list, acc_rates = [], [], []
    for cid, (c, ll, acc, llm) in enumerate(results, 1):       # <<< PATCH â‘¤
        chain_list.append(c); loglike_list.append(ll); acc_rates.append(acc)
        print(f"é“¾ {cid}: æ¥å—ç‡={acc:.2f}, LLå‡å€¼={llm:.1f}")
    # === â˜… ç»“æœè§£åŒ… =================================================
   
    # === â˜… æ‰“å°æ¯æ¡é“¾æŒ‡æ ‡å¹¶ä¸€æ¬¡æ€§è§£åŒ… ===============================
    for cid, (c, ll, acc, llm) in enumerate(results, 1):
        print(f"é“¾ {cid}: æ¥å—ç‡={acc:.2f}, LLå‡å€¼={llm:.1f}")

    chain_list, loglike_list, acc_rates, ll_means = map(list, zip(*results))
    print("\né‡‡æ ·å®Œæˆï¼Œå„é“¾æ¥å—ç‡:", acc_rates)

# # === 8. åˆ†æ®µè¯Šæ–­è¡¨  (è¡Œå·â‰ˆ260) ===================================
# report_rows = []
# for draws in range(checkpoint_int, n_iter+1, checkpoint_int):
#     posterior = {
#         name: np.stack([c[:draws, idx] for c in chain_list])
#         for idx, name in enumerate(param_names)
#     }
#     idata = az.from_dict(posterior=posterior)
#     summ  = az.summary(idata, var_names=param_names, filter_vars="like")
#     max_rhat = float(summ['r_hat'].max())
#     min_ess  = int(summ['ess_bulk'].min())

   
#     report_rows.append(dict(Draws=draws, acc=np.mean(acc_rates),
#                             max_rhat=max_rhat, min_ess=min_ess
#                             ))
#     print(f"ğŸ“Š {draws:,} draws | rÌ‚={max_rhat:.3f} | ESS={min_ess} ")
#     # === 7. åéªŒåˆå¹¶ ===============================================
    # === 7. åéªŒåˆå¹¶ & R-hat åˆåˆ¤ ===================================
    post_list = [c[burn_in::thin] for c in chain_list]

    import pickle, os
    os.makedirs('/nfs/home/y18300744/MTXmodel/saved_result', exist_ok=True)

    for k, pc in enumerate(post_list, 1):          # post_list é‡Œæ˜¯ burn-in åæ ·æœ¬
        theta_k = pc.mean(axis=0)                  # å•é“¾åéªŒå‡å€¼
            # âœ… ä¿å­˜è¯¥é“¾ burn-in åçš„å®Œæ•´åéªŒæ ·æœ¬
        draw_path = f"/nfs/home/y18300744/MTXmodel/saved_result/chain{k}_draws0628.pkl"
        with open(draw_path, "wb") as f:
            pickle.dump(pc, f)
        print(f"é“¾ {k} åéªŒæ ·æœ¬å·²ä¿å­˜ âœ {draw_path}")
        
        # â˜… æ–°å¢ï¼šæ ¼å¼åŒ–æ‰“å°åˆ°ç»ˆç«¯ â˜…
        print(f"\nåéªŒå‡å€¼å‚æ•° â€” é“¾ {k}")
        for name, val in zip(param_names, theta_k):
            print(f"{name:<12s}{val:>12.6g}")
        path_k  = f"/nfs/home/y18300744/MTXmodel/saved_result/chain{k}_params0628.pkl"
        pickle.dump(theta_k, open(path_k, "wb"))   # ä¿å­˜
        print(f"é“¾ {k} åéªŒå‡å€¼å·²ä¿å­˜ âœ {path_k}")
    # =========================================================

    post_all  = np.concatenate(post_list, axis=0)               # â˜… æ–°å¢
    theta_post_mean = post_all.mean(axis=0)                     # â˜… æ–°å¢
    draws_per_chain = post_list[0].shape[0]
    posterior_dict = {
        name: np.stack([pc[:, idx] for pc in post_list])
        for idx, name in enumerate(param_names)
    }
    import arviz as az

# === PATCH-1 : å¹¶è¡Œé‡‡æ ·ä¸å˜ï¼Œå¾—åˆ° results åç»§ç»­ ===
# â†“â†“â†“ è¿™æ®µåœ¨åŸè„šæœ¬ print æ±‡æ€»ä¹‹åæ’å…¥ â†“â†“â†“
# ------------------------------------------------------------
import arviz as az, pandas as pd, os, datetime
report_rows = []                              # å­˜è¿­ä»£-è¯Šæ–­æ±‡æ€»

# â€”â€” æŠŠå››æ¡é“¾æ‹¼æˆ (chain, draw, dim) æ–¹ä¾¿åˆ†æ®µåˆ†æ â€”â€”
chains_np = np.stack(chain_list)              # shape = (4 , n_iter , 11)

for k in range(step_report, n_iter + 1, step_report):
    # === PATCH-2 : æ„é€  ArviZ InferenceData =========
    post_slice = [c[:k] for c in chain_list]          # æ¯é“¾å‰ k draws
    posterior   = {
        name: np.stack([pc[:, idx] for pc in post_slice])
        for idx, name in enumerate(param_names)
    }
    idata_k = az.from_dict(posterior=posterior)

    summ_k   = az.summary(idata_k, var_names=param_names,
                          round_to=4, filter_vars="like")
    max_rhat = summ_k['r_hat'].max()
    min_ess  = summ_k['ess_bulk'].min()

    ts = datetime.datetime.now().strftime('%Y-%m-%dâ€†%H:%M')
    report_rows.append(dict(
        æ—¶åˆ»=ts, Draws=k, max_rhat=float(max_rhat), min_ess=int(min_ess)))

    print(f"\nğŸ“Š è¿­ä»£ {k:,}:  max rÌ‚={max_rhat:.3f},  min ESS={min_ess:.0f}")



    # idata   = az.from_dict(posterior=posterior_dict)
    # summary = az.summary(idata, var_names=param_names,
    #                      round_to=4, filter_vars="like")       # <<< PATCH â‘¥

    # print("\n=== ArviZ æ”¶æ•›è¯Šæ–­ (R-hat åˆåˆ¤) ===")
    # print(summary[['mean','r_hat','ess_bulk','ess_tail']])
    # # ----------------------------------------------------------------

    # print("\n=== ArviZ æ”¶æ•›è¯Šæ–­ ===")
    # print(summary[['mean','r_hat','ess_bulk','ess_tail']])

    # if (summary['r_hat'] > 1.01).any():
    #     print("âš ï¸  å­˜åœ¨ r_hat > 1.01ï¼Œå»ºè®®å»¶é•¿é‡‡æ ·æˆ–è°ƒæ­¥é•¿ã€‚")
    # else:
    #     print("âœ…  r_hat å…¨éƒ¨ â‰¤ 1.01ï¼Œæ”¶æ•›è‰¯å¥½ã€‚")
    # az.plot_trace(idata)

    # === PATCH-3 : å†™ Excel ===============================
    rep_df = pd.DataFrame(report_rows)
    out_xlsx = "/nfs/home/y18300744/MTXmodel/saved_result/mcmc_diag_0628.xlsx"
    rep_df.to_excel(out_xlsx, index=False)
    print(f"\nâœ… è¯Šæ–­è¡¨å·²ä¿å­˜ âœ {out_xlsx}")
    # ------------------------------------------------------------


    plt.tight_layout()
    plt.savefig("/nfs/home/y18300744/MTXmodel/saved_result/mcmc_traceplot0628.png", dpi=300)
    plt.close()

    # === 8. ä¿å­˜åéªŒå‡å€¼ ============
    #os.makedirs('saved_result', exist_ok=True)
    out_path = '/nfs/home/y18300744/MTXmodel/saved_result/mcmc_params0628.pkl'
    with open(out_path,'wb') as f:
        pickle.dump(theta_post_mean, f)
    print(f"\nğŸŒŸ å·²ä¿å­˜åˆ° {out_path}")

    # ------------------------------------------------------------------
    # === 9. æ‰“å°â€œæœ€ç»ˆä¼˜åŒ–å‚æ•°å¯¹æ¯”â€è¡¨ ==================================
    import pandas as pd
    from init_param import init_pars            # â† è¿™æ˜¯ä½ è„šæœ¬é‡ŒåŸå§‹åŸºçº¿å‘é‡

    df_param = pd.DataFrame({
        'å‚æ•°': pd.Series(param_names),
        'åˆå§‹å‚æ•°å€¼': pd.Series(theta_start),               # æ³¨ï¼šè‹¥æƒ³æ¯” Powell å…ˆéªŒå°±æ¢æˆ theta_start
        'MCMCå‡å€¼':  pd.Series(theta_post_mean)
    })

    print("\n=== ğŸ† æœ€ç»ˆä¼˜åŒ–å‚æ•°å¯¹æ¯”ï¼ˆMCMCï¼‰ğŸ† ===")
    print(df_param.to_string(index=False))