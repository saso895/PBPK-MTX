"""
è‡ªå†™ Metropolis-Hastings é‡‡æ ·å™¨ï¼Œç”¨ 0427_Powell åˆæ­¥æ‹Ÿåˆç»“æœåšå…ˆéªŒä¸­å¿ƒã€‚
é‡‡å®Œé“¾åæŠŠåéªŒå‡å€¼ä¿å­˜ä¸º saved_result/mcmc_params0427.pklï¼Œ
å¯ç›´æ¥è¢« Simu.py / simu_plot.py è°ƒç”¨ã€‚
è¿è¡Œæ–¹å¼:
    python mcmc_metropolis0427.py
"""

import numpy as np
from tqdm import tqdm, trange
import pickle, time, os, datetime,pandas as pd
from scipy.integrate import odeint
from joblib import Parallel, delayed
import matplotlib.pyplot as plt
from scipy.integrate import solve_ivp
#from tqdm.contrib.concurrent import tqdm_joblib   # è®© joblib ä¹Ÿå¸¦æ€»è¿›åº¦æ¡


# === 1. å¼•å…¥ä½ ç°æœ‰çš„æ¨¡å‹ / æ•°æ® / å¸¸é‡ ===========================
from init_param import (QRest, QK, QL, QPlas, VRest, VK, VL, VPlas,
                        init_pars)
from init_data_point4 import (time_points_train, concentration_data_train,
                              input_dose_train, inject_timelen_train)

# ---------- ä¸ modfit0610.py ä¸­ä¸€è‡´ ----------
def derivshiv(y, t, parms, R, T_total):
    PRest, PK, PL, Kbile, GFR, Free, Vmax_baso, Km_baso, Kurine, Kreab = parms
    input_rate = R if t <= T_total else 0
    ydot = np.zeros(7)
    ydot[0] = (QRest * y[3] / VRest / PRest) + (QK * y[2] / VK / PK) \
            + (QL * y[1] / VL / PL) - (QPlas * y[0] / VPlas) \
            + Kreab * y[4] + input_rate / VPlas
    ydot[1] = QL * (y[0]/VPlas - y[1]/VL/PL) - Kbile * y[1]
    ydot[2] = QK * (y[0]/VPlas - y[2]/VK/PK) - y[0]/VPlas*GFR*Free \
            - (Vmax_baso * y[2] / VK / PK) / (Km_baso + y[2]/VK/PK)
    ydot[3] = QRest * (y[0]/VPlas - y[3]/VRest/PRest)
    ydot[4] = y[0]/VPlas*GFR*Free + (Vmax_baso*y[2]/VK/PK)/(Km_baso+y[2]/VK/PK) \
            - y[4]*Kurine - Kreab*y[4]
    ydot[5] = Kurine * y[4]
    ydot[6] = Kbile * y[1]
    return ydot
def FIT_model(t, D_total, T_total, *params):
    R = D_total / T_total
    y0 = np.zeros(7)
    
    def rhs(ti, yi):
        return derivshiv(yi, ti, params, R, T_total)
    try:
        sol = solve_ivp(rhs, (t[0], t[-1]), y0,
                        t_eval=t, method='LSODA',
                        rtol=1e-6, atol=1e-9,
                        max_step=0.2)
    except Exception:
        return np.full_like(t, np.nan)  # æ˜¾å¼å¤±è´¥å€¼
    if not sol.success or np.any(np.isnan(sol.y[0])) or np.any(np.isinf(sol.y[0])):
        return np.full_like(t, np.nan)  # æ˜ç¡®å¤±è´¥å¤„ç†

    return sol.y[0] / VPlas

# ---------------------------------------------------------------

# === 2. è¯»å…¥ 0427_Powell å…ˆéªŒä¸­å¿ƒ ===============================
with open('/nfs/home/y18300744/MTXmodel/saved_result/optimized_params0427_Powell.pkl', 'rb') as f:
    theta_start = pickle.load(f)          # 10 ç»´ ndarray

param_names = ["PRest","PK","PL","Kbile","GFR","Free",
               "Vmax_baso","Km_baso","Kurine","Kreab"]
sigma_start   = 0.6   # ç»™ä¸ªç»éªŒå€¼ï¼šæ®‹å·®(log)çš„SDâ‰ˆ0.5â€“1.0
theta_start   = np.append(theta_start, sigma_start)   # å˜æˆ 11 ç»´
param_names  += ['sigma']  

# === 3. Likelihoodï¼ˆå‡è®¾æ®‹å·® ~ N(0, ÏƒÂ²)ï¼ŒÏƒÂ² å– 1ï¼‰ = -0.5 * RSS ===
def log_likelihood(theta):
    sigma = theta[-1]
    if sigma <= 0:                # æ‹’ç»è´Ÿ Ïƒ
        return -np.inf
    rss = 0.0
    n_tot = 0
    for tp, conc, dose, tinf in zip(time_points_train,
                                    concentration_data_train,
                                    input_dose_train,
                                    inject_timelen_train):
        pred = FIT_model(tp, dose, tinf, *theta[:-1])
        if np.any(np.isnan(pred)) or np.any(np.isinf(pred)):
            return -np.inf

        # â€”â€” é˜²æ­¢ log(0)
        EPS  = 1e-6
        pred = np.clip(pred, EPS, None)
        conc = np.clip(conc, EPS, None)

        diff = np.log(pred) - np.log(conc)
        rss += np.sum(diff**2)
        n_tot += diff.size

    # åŒæ­¥æ›´æ–° Ïƒ çš„å…ˆéªŒï¼ˆåŠ Cauchy æˆ– Inv-Gammaï¼‰
    return -0.5*rss/sigma**2 - n_tot*np.log(sigma)

# === 4. Proposalï¼šå¯¹ log(Î¸) åšéšæœºæ¸¸èµ°ï¼Œé«˜ç»´å…±çº¿æ›´ç¨³ ==========
theta_log_start = np.log(theta_start)
step_sizes = 0.05 * np.ones_like(theta_log_start)   # 5% æŠ–åŠ¨ï¼›å¯å¾®è°ƒ

def propose(current_log, rng):
    return current_log + rng.normal(scale=step_sizes)

# === 5. é‡‡æ ·å‚æ•° ===============================================
jit_scale = 0.02        # <-- åˆå§‹æŠ–åŠ¨å¹…åº¦ (log ç©ºé—´Â±5 %)
n_iter   = 50000       # æ€»è¿­ä»£
burn_in  = 5000       # ä¸¢å¼ƒå‰ burn_in
thin     = 10          # æ¯ thin å–ä¸€æ¬¡ï¼Œå‡å°‘è‡ªç›¸å…³
rng = np.random.default_rng(seed=20240610)
n_chain = 4

# === 6. å•é“¾é‡‡æ ·å‡½æ•° ==============================================
def run_chain(seed,chain_id=None, progress_bar=True):
    rng = np.random.default_rng(seed)
    chain   = np.empty((n_iter, len(theta_start)))
    loglike = np.empty(n_iter)
 
    curr_log   = theta_log_start + rng.normal(scale=jit_scale)#â˜…â˜… ä¿®æ”¹ 
    curr_theta = np.exp(curr_log)
    curr_ll    = log_likelihood(curr_theta)
    accept_cnt = 0

    iters = tqdm(range(n_iter), desc=f"Chain {chain_id}", leave=False)

    for i in iters:
        prop_log   = propose(curr_log, rng)#â˜…â˜… ä¿®æ”¹ 
        prop_theta = np.exp(prop_log)
        prop_ll    = log_likelihood(prop_theta)

        if np.log(rng.random()) < (prop_ll - curr_ll):#â˜…â˜… ä¿®æ”¹ 
            curr_log, curr_theta, curr_ll = prop_log, prop_theta, prop_ll
            accept_cnt += 1

        chain[i]   = curr_theta
        loglike[i] = curr_ll

    acc_rate = accept_cnt / n_iter
    ll_mean  = loglike[burn_in:].mean()        # <<< PATCH â‘¢
    return chain, loglike, acc_rate,ll_mean
# === 6b. å¤šé“¾è¿è¡Œ ================================================
from tqdm import tqdm
# ==== â˜… æ–°å¢ï¼šå¹¶è¡Œé‡‡æ ·æ‰€éœ€ ====
from joblib import Parallel, delayed          # â˜…

if __name__ == "__main__":
    results = Parallel(n_jobs=n_chain, prefer="processes")(    # <<< PATCH â‘£
        delayed(run_chain)(seed=20240611 + cid, chain_id=cid+1)
        for cid in range(n_chain)
    )
    chain_list, loglike_list, acc_rates = [], [], []
    for cid, (c, ll, acc, llm) in enumerate(results, 1):       # <<< PATCH â‘¤
        chain_list.append(c); loglike_list.append(ll); acc_rates.append(acc)
        print(f"é“¾ {cid}: æ¥å—ç‡={acc:.2f}, LLå‡å€¼={llm:.1f}")
    # === â˜… ç»“æœè§£åŒ… =================================================
    #chain_list, loglike_list, acc_rates = map(list, zip(*results))  # â˜…
    # === â˜… æ‰“å°æ¯æ¡é“¾æŒ‡æ ‡å¹¶ä¸€æ¬¡æ€§è§£åŒ… ===============================
    for cid, (c, ll, acc, llm) in enumerate(results, 1):
        print(f"é“¾ {cid}: æ¥å—ç‡={acc:.2f}, LLå‡å€¼={llm:.1f}")

    chain_list, loglike_list, acc_rates, ll_means = map(list, zip(*results))
    # === 7. åéªŒåˆå¹¶ ===============================================
    # === 7. åéªŒåˆå¹¶ & R-hat åˆåˆ¤ ===================================
    post_list = [c[burn_in::thin] for c in chain_list]

    import pickle, os
    os.makedirs('/nfs/home/y18300744/MTXmodel/saved_result', exist_ok=True)

    for k, pc in enumerate(post_list, 1):          # post_list é‡Œæ˜¯ burn-in åæ ·æœ¬
        theta_k = pc.mean(axis=0)                  # å•é“¾åéªŒå‡å€¼
        # â˜… æ–°å¢ï¼šæ ¼å¼åŒ–æ‰“å°åˆ°ç»ˆç«¯ â˜…
        print(f"\nåéªŒå‡å€¼å‚æ•° â€” é“¾ {k}")
        for name, val in zip(param_names, theta_k):
            print(f"{name:<12s}{val:>12.6g}")
        path_k  = f"/nfs/home/y18300744/MTXmodel/saved_result/chain{k}_params.pkl"
        pickle.dump(theta_k, open(path_k, "wb"))   # ä¿å­˜
        print(f"é“¾ {k} åéªŒå‡å€¼å·²ä¿å­˜ âœ {path_k}")
    # =========================================================

    post_all  = np.concatenate(post_list, axis=0)               # â˜… æ–°å¢
    theta_post_mean = post_all.mean(axis=0)                     # â˜… æ–°å¢
    draws_per_chain = post_list[0].shape[0]
    posterior_dict = {
        name: np.stack([pc[:, idx] for pc in post_list])
        for idx, name in enumerate(param_names)
    }
    import arviz as az
    idata   = az.from_dict(posterior=posterior_dict)
    summary = az.summary(idata, var_names=param_names,
                         round_to=4, filter_vars="like")       # <<< PATCH â‘¥

    print("\n=== ArviZ æ”¶æ•›è¯Šæ–­ (R-hat åˆåˆ¤) ===")
    print(summary[['mean','r_hat','ess_bulk','ess_tail']])
    # ----------------------------------------------------------------

    print("\n=== ArviZ æ”¶æ•›è¯Šæ–­ ===")
    print(summary[['mean','r_hat','ess_bulk','ess_tail']])

    if (summary['r_hat'] > 1.01).any():
        print("âš ï¸  å­˜åœ¨ r_hat > 1.01ï¼Œå»ºè®®å»¶é•¿é‡‡æ ·æˆ–è°ƒæ­¥é•¿ã€‚")
    else:
        print("âœ…  r_hat å…¨éƒ¨ â‰¤ 1.01ï¼Œæ”¶æ•›è‰¯å¥½ã€‚")
    az.plot_trace(idata)
    plt.tight_layout()
    plt.savefig("/nfs/home/y18300744/MTXmodel/saved_result/mcmc_traceplot0619.png", dpi=300)
    plt.close()

    # === 8. ä¿å­˜åéªŒå‡å€¼ ============
    #os.makedirs('saved_result', exist_ok=True)
    out_path = '/nfs/home/y18300744/MTXmodel/saved_result/mcmc_params0619.pkl'
    with open(out_path,'wb') as f:
        pickle.dump(theta_post_mean, f)
    print(f"\nğŸŒŸ å·²ä¿å­˜åˆ° {out_path}")

    # ------------------------------------------------------------------
    # === 9. æ‰“å°â€œæœ€ç»ˆä¼˜åŒ–å‚æ•°å¯¹æ¯”â€è¡¨ ==================================
    import pandas as pd
    from init_param import init_pars            # â† è¿™æ˜¯ä½ è„šæœ¬é‡ŒåŸå§‹åŸºçº¿å‘é‡

    df_param = pd.DataFrame({
        'å‚æ•°': pd.Series(param_names),
        'åˆå§‹å‚æ•°å€¼': pd.Series(theta_start),               # æ³¨ï¼šè‹¥æƒ³æ¯” Powell å…ˆéªŒå°±æ¢æˆ theta_start
        'MCMCå‡å€¼':  pd.Series(theta_post_mean)
    })

    print("\n=== ğŸ† æœ€ç»ˆä¼˜åŒ–å‚æ•°å¯¹æ¯”ï¼ˆMCMCï¼‰ğŸ† ===")
    print(df_param.to_string(index=False))