# -*- coding: utf-8 -*-
"""
lake_sens02_plus.py â€”â€” åœ¨ä¸€æ¬¡æ•æ„Ÿæ€§+å…±çº¿æ€§åˆ†æåŸºç¡€ä¸Šï¼Œ
                      è®¡ç®— Table-8 é£æ ¼çš„å‚æ•°æ ‡å‡†è¯¯å·® & ç›¸å…³ç³»æ•°
-------------------------------------------------------------------
æ–°å¢ Step-5:
  Â· é€‰å®šä¸€ä¸ªå‚æ•°å­é›† (é»˜è®¤å–å…¨å±€çµæ•åº¦æœ€é«˜çš„ 7 ä¸ª)
  Â· æ„é€ â€œåŠ æƒé›…å¯æ¯”â€ J_w  (ä¸ WSS ä¸­çš„åŠ æƒæ–¹å¼ä¸€è‡´)
  Â· ç”¨ (J_w^T J_w)^-1 ä¼°è®¡åæ–¹å·®çŸ©é˜µï¼Œç»™å‡º:
      - ç›¸å¯¹æ ‡å‡†è¯¯å·® (%)
      - å‚æ•°é—´ç›¸å…³ç³»æ•° Ï_jk
  Â· ç»“æœæ‰“å° + å†™å…¥ table8_stats.csv
-------------------------------------------------------------------
å…¶ä½™ Step-1ï½Step-4 ä¸åŸæ–‡ä»¶å®Œå…¨ä¸€è‡´ã€‚
"""

import itertools, math, numpy as np, pandas as pd, matplotlib.pyplot as plt
from scipy.integrate import odeint
import numpy.linalg as la                     # è§£å†³ la
from scipy.optimize import least_squares      # è§£å†³ least_squares
from numpy.random import default_rng  
import numpy as np 
import os,pickle,datetime
from tqdm import tqdm

# >>> MOD 0 : æ–°å¢ SALib ä¾èµ–
from SALib.sample import morris as morris_sample
from SALib.analyze import morris as morris_analyze
# <<< MOD 0 --------------------------------------------------

today_date = datetime.datetime.now().strftime('%Y-%m-%d')

# --------------------------------------------------------------
# 0. è½½å…¥å›ºå®š/å¯è°ƒå‚æ•° & ç—…äººç»™è¯æ•°æ®
# --------------------------------------------------------------
from init_param import (
    QRest, QK, QL, QPlas, VRest, VK, VL, VPlas,
    PRest, PK, PL, Kbile, GFR, Free,
    Vmax_baso, Km_baso, Kurine, Kreab
)
from init_data_point4 import (
    time_points_train as time_groups,
    input_dose_train  as dose_groups,
    inject_timelen_train as tinf_groups,
    concentration_data_train as conc_groups,
)

param_names = [
    "PRest", "PK", "PL", "Kbile", "GFR",
    "Free",  "Vmax_baso", "Km_baso", "Kurine", "Kreab",
]
baseline_init = np.array([
    PRest, PK, PL, Kbile, GFR,
    Free,  Vmax_baso, Km_baso, Kurine, Kreab,
], dtype=float)
LOCKED = ["Km_baso"] 
# --------------------------------------------------------------
# 1. PBPK æ–¹ç¨‹ & æ¨¡æ‹Ÿå‡½æ•°
# --------------------------------------------------------------
def derivshiv(y, t, parms, R, T_total):
    PRest, PK, PL, Kbile, GFR, Free, Vmax_baso, Km_baso, Kurine, Kreab = parms
    inp = R if t <= T_total else 0
    dy  = np.zeros(7)
    dy[0] = (
        QRest * y[3] / VRest / PRest
        + QK * y[2] / VK / PK
        + QL * y[1] / VL / PL
        - QPlas * y[0] / VPlas
        + Kreab * y[4]
        + inp #/ VPlas
    )
    dy[1] = QL * (y[0] / VPlas - y[1] / VL / PL) - Kbile * y[1]
    dy[2] = (
        QK * (y[0] / VPlas - y[2] / VK / PK)
        - y[0] / VPlas * GFR * Free
        - (Vmax_baso * y[2] / VK / PK) / (Km_baso + y[2] / VK / PK)
    )
    dy[3] = QRest * (y[0] / VPlas - y[3] / VRest / PRest)
    dy[4] = (
        y[0] / VPlas * GFR * Free
        + (Vmax_baso * y[2] / VK / PK) / (Km_baso + y[2] / VK / PK)
        - y[4] * Kurine
        - Kreab * y[4]
    )
    dy[5] = Kurine * y[4]
    dy[6] = Kbile * y[1]
    return dy

def FIT_model(t, dose, tinf, *params):
    R = dose / tinf
    y0 = np.zeros(7)
    sol = odeint(
        derivshiv, y0, t,
        args=(params, R, tinf),
        rtol=1e-6, atol=1e-9, h0=0.1,
    )
    return sol[:, 0] / VPlas   # è¡€æµ†æµ“åº¦

# =======================================================================
# ğŸ”„ å¤–å±‚å¾ªç¯ï¼šé‡å¤ Step-1 ~ Step-6 ç›´åˆ°å­é›†ç¨³å®š & Î³_max â‰¤ é˜ˆå€¼
# =======================================================================
gamma_thresh = 10.0          # å…±çº¿æ€§æ”¶æ•›é˜ˆå€¼
max_outer    = 8             # æœ€å¤šå¾ªç¯æ¬¡æ•°
last_subset  = None          # è®°å½•å‰ä¸€è½®å­é›†
baseline = baseline_init.copy()  
for outer in range(max_outer):
    print(f"\n========  å¤–å±‚å¾ªç¯ {outer+1}/{max_outer}  ========")
    # --------------------------------------------------------------
    # --------------------------------------------------------------
    # >>> MOD 1 : Step-1 â€”â€” Morris å…¨å±€çµæ•åº¦ (SALib)
    # --------------------------------------------------------------
    # ---------- å°è£…ï¼šå•æ¬¡æ¨¡å‹è¯„ä¼° ----------
    def model_eval(theta_vec):
        """
        theta_vec: 1-D ndarray (n_param,)
        è¿”å›æ‹¼æ¥åœ¨ä¸€èµ·çš„æ‰€æœ‰å®éªŒè¾“å‡º (flatten)
        """
        out = []
        for tt, d, ti in zip(time_groups, dose_groups, tinf_groups):
            out.extend(FIT_model(tt, d, ti, *theta_vec))
        return np.asarray(out) 
    
    print("\n=== Step-1  Morris å…¨å±€çµæ•åº¦ (SALib) ===")

    # *1.1* å®šä¹‰ SALib problem å­—å…¸ï¼ˆç”¨ Â±30% ä½œä¸Šä¸‹ç•Œï¼Œç¤ºä¾‹ï¼‰
    bounds = np.column_stack([
        baseline * 0.7,
        baseline * 1.3
    ])

    # ====== â˜† ç”Ÿ ç† ä¸Š ä¸‹ é™ â˜† ======
    limit_dict = {
        "PRest": (0.5, 3.0),
        "PK":    (1.0, 4.0),
        "PL":    (1.0, 8.0),
        "Kbile": (0.01, 0.3),
        "GFR":   (30, 150),
        "Free":  (0.05, 0.15),
        "Vmax_baso": (0.1, 1e3),
        "Km_baso":   (1, 500),
        "Kurine":    (0.01, 10),
        "Kreab":     (0.0, 1),
    }
    # --- è¦†å†™ bounds ä¸­å—é™å‚æ•° ---
    for i, pname in enumerate(param_names):
        if pname in limit_dict:
            bounds[i, 0] = limit_dict[pname][0]        # ä¸‹é™
            bounds[i, 1] = limit_dict[pname][1]        # ä¸Šé™

    problem = dict(num_vars=len(param_names),
               names=param_names,
               bounds=bounds.tolist())

    # *1.2* ç”Ÿæˆ Morris é‡‡æ ·
    N_TRAJ   = 40      # è½¨è¿¹æ¡æ•°ï¼Œå¯è§†æƒ…å†µè°ƒ
    X = morris_sample.sample(problem, N_TRAJ, num_levels=4,
                              optimal_trajectories=None)
    
    print("æ¨¡å‹æ‰¹é‡è¿è¡Œ â€¦")
    Y_full = np.array([model_eval(row) for row in tqdm(X)])   # (1200, M)

    # â˜…â˜…â˜… å…³é”®æ”¹åŠ¨ï¼šæŠŠå¤šè¾“å‡ºå‹ç¼©æˆä¸€ç»´æ ‡é‡ â˜…â˜…â˜…
# === MOD BEGIN Step-1 æŒ‡æ ‡å¯¹é½ï¼ˆAUC â†’ log-RMSEï¼‰ ====================
    # â‘  æŠŠè§‚æµ‹æµ“åº¦å±•å¹³æˆä¸€ç»´
    obs_flat = np.concatenate(conc_groups)                       # (M,)
    obs_clip  = np.clip(obs_flat, 1e-9, None)
    # â‘¡ å¯¹æ¯æ¡é‡‡æ ·çš„é¢„æµ‹æ›²çº¿è®¡ç®— log10-RMSE
    pred_flat = Y_full.reshape(Y_full.shape[0], -1) 
    pred_clip = np.clip(pred_flat, 1e-9, None)             # (N, M)
    log_err   = np.log10(pred_clip  + 1e-9) - np.log10(obs_clip)  # é¿å… log(0)
    Y_scalar  = np.sqrt(np.mean(log_err**2, axis=1))             # (N,)

# === MOD END Step-1 ===================================================

    # *1.4* Morris åˆ†æï¼šå¯¹æ¯ä¸ª time-point å–å‡æ–¹æ ¹åå†æ±‡æ€»
    Si = morris_analyze.analyze(problem, X, Y_scalar, 
                                     conf_level=0.95,
                                     print_to_console=False)

    mu_star = Si['mu_star']      # â‘  ç»å¯¹å‡å€¼
    sigma    = Si['sigma']
    # è¾“å‡ºç»“æœ
    gsa_df = pd.DataFrame({
        'param'  : param_names,
        'mu_star': mu_star,
        'sigma'  : sigma
    })
    gsa_df.to_csv(f'saved_result/morris_result{today_date}.csv', index=False)
    print(gsa_df.sort_values('mu_star', ascending=False))

    infl_mask = mu_star >= 0.1
    param_ids = np.where(infl_mask)[0]

    # === NEWï¼šé”å®šä¸æƒ³å‚ä¸åç»­ Î³ ä¸æ‹Ÿåˆçš„å‚æ•° =====================
    #lock = ["Km_baso"]                           # éœ€è¦å›ºå®šçš„å‚æ•°åï¼Œå¯ä¸€æ¬¡å†™å¤šä¸ª
    param_ids = [i for i in param_ids
             if param_names[i] not in LOCKED]  # è¿‡æ»¤æ‰é”å®šé¡¹
 
    print(f"â˜… Morris ä¿ç•™ä¸‹æ¥åš Î³ åˆ†æçš„å‚æ•°æ•°ç›®(é” {LOCKED} å): "
        f"{len(param_ids)} / {len(param_names)}")

    ### MOD 1-3 ï¼šæä¾›æ’åºæ•°ç»„ order ä¾›åé¢ç»˜å›¾ ###
    order = np.argsort(mu_star)[::-1]

    # ==================================================
    # Step-2  Î³_max / å…±çº¿æ€§åˆ†æ
    # ==================================================
    def local_sensitivity(theta_base, eps=1e-6):
        """
        è®¡ç®—å±€éƒ¨çµæ•åº¦çŸ©é˜µ S  (n_out, n_param)
        Forward differenceï¼›eps å¯æ”¹ä¸º 1e-20j ä½¿ç”¨å¤æ­¥
        """
        y0 = model_eval(theta_base)
        n_out, n_par = y0.size, theta_base.size
        S = np.empty((n_out, n_par))
        for j in range(n_par):
            tpert = theta_base.copy()
            tpert[j] *= (1.0 + eps)
            y1 = model_eval(tpert)
            S[:, j] = (y1 - y0) / (theta_base[j] * eps)
        return S

    print("\n[Step-2] è®¡ç®—å±€éƒ¨çµæ•åº¦çŸ©é˜µ & Î³_max")
    theta0 = baseline.copy()            # åŸºçº¿å­é›†
    sl_vectors = local_sensitivity(theta0) # ç”¨ä½œåç»­ Î³ è®¡ç®—
    unit_vecs  = [v/la.norm(v) for v in sl_vectors.T]      # æ³¨æ„è½¬ç½®(.T)
    
    def gamma(idxs):
        S = np.column_stack([unit_vecs[i] for i in idxs])#å…¬å¼7çš„å°sæ„é€ å‡ºå¤§S
        lam_min = np.min(np.linalg.eigvals(S.T @ S).real)#å…¬å¼8æ ¹å·é‡Œçš„å†…å®¹
        return 1/math.sqrt(lam_min)#å…¬å¼8æœ€ç»ˆç»“æœ

    # ========= Î³-Envelope å›¾ï¼ˆå¯é€‰ï¼‰ =========
    plt.figure(figsize=(6,4))
    for k in range(1, len(param_names)+1):
        g_all = [gamma(c) for c in itertools.combinations(range(len(param_names)), k)]
        plt.plot([k]*len(g_all), g_all, 'k.', alpha=.4, ms=3)
    # â€œTop-nâ€ æ›²çº¿
    topn_gamma = [gamma(tuple(order[:k])) for k in range(1, len(order)+1)]
    plt.plot(range(1,11), topn_gamma[:10], 'r-s', lw=2, label='Top-n')
    plt.axhline(10, ls='--', c='r')
    plt.xlabel('Subset size k')
    plt.ylabel('Î³')
    plt.tight_layout()
    save_path =f'saved_result/gamma_{today_date}_{outer+1}.png' 
    plt.savefig(save_path, dpi=300)
    #plt.show()
    # --------------------------------------------------------------
    # 4. Step-3 â€”â€” æ‰€æœ‰ Î³ å†™ Excel (ä¿æŒåŸå…ˆç‰ˆæœ¬)
    # --------------------------------------------------------------
    allowed = [i for i, name in enumerate(param_names) if name not in LOCKED]
    rows = []
    for k in range(1, len(allowed) + 1):
        for idxs in itertools.combinations(allowed, k):
            g = gamma(idxs)
            subset_names = ", ".join(param_names[i] for i in idxs)
            rows.append({"Subset size": k, "Parameters": subset_names, "Gamma": g})   
    print("å·²ç”Ÿæˆ gamma_subsets.xlsx â€”â€” è¯·åœ¨æœ¬ç›®å½•æŸ¥çœ‹æ‰€æœ‰å­é›† Î³ å€¼")
    # è½¬ DataFrame
    GammaDF = pd.DataFrame(rows)
    print(f"Î³_max æœ¬å¾ªç¯ = {GammaDF['Gamma'].max():.1f}")
    # æŒ‰å­é›†å¤§å°åˆ†å·¥ä½œè¡¨å†™å…¥
    save_path =f'saved_result/gamma_subsets{today_date}.xlsx' 
    with pd.ExcelWriter(save_path, engine="openpyxl") as writer:
        for k, grp in GammaDF.groupby("Subset size"):
            grp_sorted = grp.sort_values("Gamma", ascending=False)
            grp_sorted.to_excel(writer, sheet_name=f"size_{k}", index=False)
    print("å·²ç”Ÿæˆ gamma_subsets.xlsx â€”â€” è¯·åœ¨æœ¬ç›®å½•æŸ¥çœ‹æ‰€æœ‰å­é›† Î³ å€¼")
    # --------------------------------------------------------------
    # 5. è¿½åŠ  Step-5 â€”â€” è¿‘ä¼¼æ ‡å‡†è¯¯å·® & ç›¸å…³ç³»æ•° (Table 8)
    # --------------------------------------------------------------
    print("\n=== Step-5  è¿‘ä¼¼æ ‡å‡†è¯¯å·® & ç›¸å…³ç³»æ•° (Table-8) ===")

    # â€”â€” 5.1 é€‰â€œè¦ä¼°è®¡çš„å­é›†â€ï¼šå¯æŒ‡å®šå…±çº¿æ€§åˆ†æç»“æœæœ€ä¼˜ç»„åˆ â€”â€”
    # ---------- è‡ªåŠ¨é€‰ â€œÎ³<é˜ˆå€¼ ä¸” k æœ€å¤§â€ çš„å‚æ•°å­é›† ----------
    #gamma_thresh = 10.0                           # é˜ˆå€¼ï¼Œä½ ä¹Ÿå¯ä»¥ä¼ å…¥å¾ªç¯å¤–çš„åŒåå˜é‡

    # Step 1: å¯¹æ¯ä¸ª kï¼Œåˆ¤æ–­è¯¥å¤§å°ä¸‹çš„æ‰€æœ‰å­é›†çš„ Î³_max æ˜¯å¦ <= é˜ˆå€¼
    valid_k = []                                   #è®°å½•å­é›†ä¸ªæ•°
    for k, grp in GammaDF.groupby("Subset size"):  #kæ˜¯å­é›†å¤§å°ï¼Œgrpæ˜¯å¯¹åº”å¤§å°æ‰€æœ‰å­é›†çš„ç»„åˆ
        if grp["Gamma"].min() <= gamma_thresh:     #æ‰€æœ‰ç»„åˆçš„æœ€å¤§gammaå€¼ï¼Œå°äº10ï¼Œå°±è®°å½•k
            valid_k.append(k)                      #å¾—åˆ°å€™é€‰çš„ä¸€ç»„k                      

    # Step 2: è‹¥æœ‰æœ‰æ•ˆçš„ k å€¼ï¼Œé€‰æœ€å¤§çš„ k
    if valid_k:
        k_max = max(valid_k)                                  #é€‰å€™é€‰çš„ä¸€ç»„ké‡Œæœ€å¤§çš„ k
        cands_k = GammaDF[(GammaDF["Subset size"] == k_max)]  #é€‰å‡ºç­‰äºæœ€å¤§kçš„å­é›†
        best_row = cands_k.loc[cands_k["Gamma"].idxmin()]     #ä»å­é›†é‡Œé€‰ä¸€ç»„gammaæœ€å°çš„å‚æ•°ç»„åˆ
        print(f"âœ… æ»¡è¶³ Î³<{gamma_thresh} çš„æœ€å¤§å‚æ•°ä¸ªæ•°ä¸º {k_max}ï¼Œé€‰ Î³ æœ€å°çš„å­é›†")
    else:
        # å¦‚æœæ‰€æœ‰å­é›†éƒ½ä¸æ»¡è¶³ï¼Œé€€è€Œæ±‚å…¶æ¬¡ï¼šé€‰æ‹© Î³ æœ€å°çš„
        best_row = GammaDF.loc[GammaDF["Gamma"].idxmin()] 
        print(f"âš ï¸ æ‰€æœ‰å­é›†éƒ½å­˜åœ¨é«˜å…±çº¿æ€§ï¼Œé€‰ Î³ æœ€å°çš„ç»„åˆï¼š{best_row['Parameters']}") 

    subset_names = [s.strip() for s in best_row["Parameters"].split(",")]
    subset_idx   = [param_names.index(p) for p in subset_names]
    gamma_sel = best_row["Gamma"]   

    print(f"âœ”ï¸è‡ªåŠ¨é€‰ä¸­å­é›† (k={len(subset_idx)}, Î³={best_row['Gamma']:.2f}):", subset_names)

    
    # ============================================================
    # 6. WSS ç›®æ ‡å‡½æ•° + æœ€å°äºŒä¹˜æ‹Ÿåˆ
    # ============================================================
    print("\n=== Stepâ€‘6  WSS ç›®æ ‡å‡½æ•° + å‚æ•°æ‹Ÿåˆä¼˜åŒ– ===")
    # ------------------------------------------------------------
    #    â”€â”€æŠŠâ€œæ¯ä¸ªäººç¬¬ 2 ä¸ªæµ“åº¦ç‚¹â€æƒé‡åŠ å€
    # ------------------------------------------------------------
    sc_groups = []
    for obs in conc_groups:                # obs æ˜¯ä¸€æ¡å®éªŒçš„è§‚æµ‹æµ“åº¦æ•°ç»„
        sc = np.ones_like(obs)             # å…ˆå…¨éƒ¨æƒé‡ = 1
        if len(sc) > 1:                    # è‹¥è‡³å°‘æœ‰ 2 ä¸ªé‡‡æ ·ç‚¹
            sc[1] = 0.1                    # è®©ç¬¬ 2 ç‚¹çš„ sc æ›´å° â†’ æƒé‡æ›´å¤§
        sc_groups.append(sc)               # (æƒé‡ âˆ 1/sc)
    # ------------------------------------------------------------
    # 6.1 è®¡ç®—å½’ä¸€åŒ–æ®‹å·®
    # ------------------------------------------------------------
    def _residuals(theta_sub):                          # theta_sub æ˜¯å¾…ä¼° n ä¸ªå‚æ•°çš„å½“å‰è¯•æ¢å€¼
        full = baseline.copy()                          # å¤åˆ¶ä¸€ä»½å…¨ 10 ç»´å‚æ•°å‘é‡
        full[subset_idx] = theta_sub                    # ç”¨è¯•æ¢å€¼æ›¿æ¢ n ç»´æ•æ„Ÿå‚æ•°å­é›†
        res = []                                        # å‡†å¤‡ç´¯è®¡æ‰€æœ‰å®éªŒçš„æ®‹å·®
        for t, d, tinf, obs,sc in zip(                  # åŒæ—¶éå†æ¯æ¡ç»™è¯å®éªŒï¼š
                time_groups, dose_groups,               #  â”œâ”€ t     â†’ é‡‡æ ·æ—¶é—´ç‚¹æ•°ç»„
                tinf_groups, conc_groups,sc_groups):    #  â”œâ”€ d,tinfâ†’ å‰‚é‡ä¸è¾“æ³¨æ—¶é•¿
            pred = FIT_model(t, d, tinf, *full)
            # === MOD BEGIN â‘¡ clip æ®‹å·® ===================================
            pred_clip = np.clip(pred, 1e-9, None)
            obs_clip  = np.clip(obs,  1e-9, None)
            res.extend((np.log10(pred_clip) - np.log10(obs_clip)) / sc)
# === MOD END =================================================
            #res.extend((np.log10(pred + 1e-9) - np.log10(obs)) / sc)
        return np.asarray(res)                          # è¿”å› 1-D æ®‹å·®å‘é‡ (æ‹¼æ¥æ‰€æœ‰å®éªŒ)

    lb = np.zeros(len(subset_idx))        # å„å‚æ•°ä¸‹ç•Œ 0ï¼ˆä¸å¯è´Ÿï¼‰
    ub = np.full(len(subset_idx), np.inf) # ä¸Šç•Œé»˜è®¤ä¸º +âˆ
    #ub[subset_names.index("Free")] = 1.0  # ç”Ÿç†çº¦æŸ Freeâ‰¤1
    for i, pname in enumerate(subset_names):
        if pname in limit_dict:           # limit_dict åœ¨ 131â€“147 è¡Œå·²ç»™å‡º
            lb[i], ub[i] = limit_dict[pname]
    # ------------------------------------------------------------
    # 6.2è®¡ç®—å½’ä¸€åŒ–æ®‹å·®
    # ------------------------------------------------------------
    #----------åœ¨ SciPy çš„ least_squares æ¡†æ¶é‡Œï¼Œâ€œå¹³æ–¹ + æ±‚å’Œâ€è¿™ä¸€åŠ¨ä½œæ˜¯ç”±æ±‚è§£å™¨è‡ªå·±å®Œæˆçš„
    # å¦‚æœ baseline ä¸­æŸäº›å‚æ•°åˆå§‹å€¼è¶…å‡º boundsï¼Œè£å‰ªåˆ°åˆæ³•èŒƒå›´
    x0 = baseline[subset_idx].copy()
    x0 = np.clip(x0, lb, ub)  # é˜²æ­¢ initial guess è½åœ¨è¾¹ç•Œå¤–
    opt = least_squares(                  #   Levenberg-Marquardt/Trust-Region éçº¿æ€§æœ€å°äºŒä¹˜æ‹Ÿåˆå‡½æ•°
        _residuals,                       #   ç›®æ ‡å‡½æ•°ï¼šåŠ æƒæ®‹å·®
        x0,
        #baseline[subset_idx],             #   åˆå€¼ï¼šåŸºçº¿ç”Ÿç†å‚æ•°
        bounds=(lb, ub),                  #   ç®€å•ç•Œé™çº¦æŸ
        method="trf",                     #   ä½¿ç”¨ trust-region reflective ç®—æ³•
        jac='3-point',
        #diff_step=baseline*1e-4,
        diff_step=np.maximum(np.abs(baseline[subset_idx])*1e-4, 1e-6),#baseline[subset_idx] * 1e-4,   # â˜… æ”¹è¿™é‡Œï¼
        x_scale='jac',
        xtol=1e-10,                       #   å‚æ•°æ­¥é•¿ (step norm) é˜ˆå€¼
        verbose=2,                        #   è¾“å‡ºè¿­ä»£ä¿¡æ¯
        max_nfev=300)                     #   æœ€å¤š 300 æ¬¡å‡½æ•°è¯„ä¼°
    theta_hat = opt.x                     #   æœ€ç»ˆæœ€å°äºŒä¹˜ä¼°è®¡å€¼ï¼Œxå°±æ˜¯ä½¿æ‹Ÿåˆè¯¯å·®æœ€å°çš„å‚æ•°å€¼ã€‚
    rss = np.sum(opt.fun**2)              #   æ®‹å·®å¹³æ–¹å’Œ (costÃ—2)ï¼Œè¿™æ˜¯æ–‡ç« ä¸­å…¬å¼ï¼ˆ1ï¼‰è®¡ç®—å‡ºæ¥çš„å€¼
    dof = len(opt.fun) - len(theta_hat)   #   è‡ªç”±åº¦ = æ•°æ®ç‚¹æ•° âˆ’ å‚æ•°æ•°
    print(f"ä¼˜åŒ–å®Œæˆ  RSS = {rss:.4g}  (DOF = {dof})")
    print(f"success : {opt.success}")        # True / False
    print(f"status  : {opt.status}")         # 0â€“5 çš„ä»£ç ï¼Œè§ SciPy æ–‡æ¡£
    print(f"message : {opt.message}")        # äººå¯è¯»çš„æ”¶æ•›è¯´æ˜
    print(f"nfev    : {opt.nfev}")           # ç›®æ ‡å‡½æ•°è¯„ä¼°æ¬¡æ•°
    baseline[subset_idx] = theta_hat  # å›å†™ä»¥ä¾¿ç»§ç»­è¿­ä»£
    print(f"ä¼˜åŒ–æ¬¡æ•°    : {outer}") 
    df_param = pd.DataFrame({
        'å‚æ•°': param_names,
        'åˆå§‹å‚æ•°å€¼': baseline_init,
        'æ‹Ÿåˆå‚æ•°å€¼':  baseline
    })
    print("\n=== å‚æ•°å¯¹æ¯” ===")
    print(df_param.to_string(index=False))
    # ---------- ç”¨æ‹Ÿåˆåå‚æ•°å†ç®— Î³ ----------
    theta_tmp = baseline.copy()
    gamma_post = gamma(subset_idx)  # â† ç”¨æ–°çš„ baseline å†ç®— Î³
    # ----------------------------------------------------------
    same_subset = (last_subset is not None) and (set(subset_idx) == set(last_subset))
    gamma_post  = gamma(subset_idx)          # å­é›† Î³
    if same_subset and (gamma_post <= gamma_thresh):
        print(f"âœ… å­é›†ç¨³å®šï¼Œä¸” Î³ = {gamma_post:.2f} â‰¤ {gamma_thresh} â†’ æ”¶æ•›")
        break

    last_subset = subset_idx.copy()
    # --------------------------------------------------------
else:
    print("âš ï¸ è¾¾åˆ°æœ€å¤§å¾ªç¯æ¬¡æ•°ä»æœªæ»¡è¶³æ”¶æ•›æ¡ä»¶")

#os.makedirs('saved_result', exist_ok=True)
save_path =f'saved_result/SA_param{today_date}.pkl' 
with open(save_path, 'wb') as f:
    pickle.dump({
        'subset_idx'  : subset_idx,
        'subset_names': subset_names,
        'baseline'    : baseline,
        'gamma_max'   : gamma_sel,
    }, f)
print(f"ğŸŒŸ ç¨³å®šå­é›† + å‚æ•°å·²ä¿å­˜ --> {save_path} ")

# â€”â€” ä¼°è®¡æœ€ä¼˜ç‚¹é™„è¿‘çš„åæ–¹å·®ï¼Œç”¨ä½œ MCMC proposal â€”â€” 
# â€”â€”ä»…å½“å­é›†ç¨³å®š & ä¼˜åŒ–æˆåŠŸåæ‰ä¼°åæ–¹å·®â€”â€”
if  opt.success:           # âœ±â‘  åŒä¿é™©
    jac = opt.jac                           # n_data Ã— n_param
    jt_j = jac.T @ jac

    # è‹¥ JTJ å¥‡å¼‚ â†’ ç”¨ä¼ªé€†
    try:
        cov = np.linalg.inv(jt_j)
    except np.linalg.LinAlgError:
        cov = np.linalg.pinv(jt_j)          # âœ±â‘¡ å¥‡å¼‚çŸ©é˜µ fallback
        print("âš ï¸  JTJ å¥‡å¼‚ï¼Œå·²ç”¨ä¼ªé€†è¿‘ä¼¼åæ–¹å·®çŸ©é˜µ")

    #os.makedirs('saved_result', exist_ok=True)
    save_path =f'saved_result/opt_cov{today_date}.pkl' 
    with open(save_path, 'wb') as f:
        pickle.dump(cov, f)
    print("ğŸ“¦ å·²ä¿å­˜åæ–¹å·®çŸ©é˜µ opt_cov.pklï¼Œå¯ä½œä¸º MCMC proposal_cov")

df_param = pd.DataFrame({
    'å‚æ•°': param_names,
    'åˆå§‹å‚æ•°å€¼': baseline_init,
    'æ‹Ÿåˆå‚æ•°å€¼':  baseline
})

print("\n=== ğŸ†æœ€ç»ˆä¼˜åŒ–å‚æ•°å¯¹æ¯”ğŸ† ===")
print(df_param.to_string(index=False))
print("\n=== ğŸŒˆoverğŸŒˆ ===")
